{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "pointed-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import model_from_json\n",
    "import cv2 as cv\n",
    "import pyautogui\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "worth-lincoln",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CARGAR MODELO\n",
    "json_file = open('data/model/output/modelboredom.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "#from keras.models import model_from_json\n",
    "modelTL = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "modelTL.load_weights(\"data/model/output/modelboredom.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "electrical-seminar",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(route):\n",
    "    original_image = route\n",
    "    grayscale_image = cv.cvtColor(original_image, cv.COLOR_BGR2GRAY)\n",
    "    grayscale_image = original_image\n",
    "\n",
    "    face_cascade = cv.CascadeClassifier('data/face_classifier.xml')\n",
    "\n",
    "    detected_faces = face_cascade.detectMultiScale(grayscale_image)\n",
    "\n",
    "    for (column, row, width, height) in detected_faces:\n",
    "        cv.rectangle(\n",
    "            original_image,\n",
    "            (column, row),\n",
    "            (column + width, row + height),\n",
    "            (0, 255, 0),\n",
    "            2\n",
    "        )\n",
    "        \n",
    "    return detected_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sensitive-timing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_face(img, face_coords):\n",
    "    x0 = face_coords[0]\n",
    "    y0 = face_coords[1]\n",
    "    \n",
    "    width = face_coords[2]\n",
    "    height = face_coords[3]\n",
    "    \n",
    "    x1 = x0 + width\n",
    "    y1 = y0 + height\n",
    "\n",
    "    return img[y0:y1, x0:x1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "toxic-portland",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_values(faces_detected, dict_faces):\n",
    "    dict_faces[\"faces\"] = faces_detected\n",
    "    dict_faces[\"msg\"] = []\n",
    "    dict_faces[\"color\"] = []\n",
    "    counter = dict()\n",
    "    counter[\"bored\"] = 0\n",
    "    counter[\"engaged\"] = 0\n",
    "    counter[\"neutral\"] = 0\n",
    "    face_number = 0\n",
    "    \n",
    "    return dict_faces, counter, face_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "special-confirmation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_state(face, frame):\n",
    "    only_face = cut_face(frame, face)\n",
    "    small_face = cv.resize(only_face, (48, 48))\n",
    "    grey_face = cv.cvtColor(small_face, cv.COLOR_BGR2GRAY)\n",
    "    flat_array = np.array(grey_face).flatten()\n",
    "    flat_array = flat_array.reshape(1, 48, 48, 1)\n",
    "    predicted_Y = modelTL.predict(flat_array)\n",
    "    predicted_state = np.argmax(predicted_Y, axis=1)[0]\n",
    "    percentage = round(predicted_Y[0][predicted_state] * 100,2)\n",
    "    \n",
    "    return predicted_state, percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instructional-douglas",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_text(detected_faces, frame, counter):\n",
    "\n",
    "    for i in range(len(detected_faces[\"faces\"])):\n",
    "        cv.putText(frame, detected_faces[\"msg\"][i] , \n",
    "                   (detected_faces[\"faces\"][i][0] +(int)(detected_faces[\"faces\"][i][2]/2), \n",
    "                    detected_faces[\"faces\"][i][1] - 10), cv.FONT_HERSHEY_DUPLEX, 1,  \n",
    "                   detected_faces[\"color\"][i] , 2)\n",
    "    cv.putText(frame, \"Bored: \" + str(counter[\"bored\"]) + \" - Neutral: \" + str(counter[\"neutral\"]) + \" - Engaged: \" + str(counter[\"engaged\"]),\n",
    "              (0,30), cv.FONT_HERSHEY_DUPLEX, 1, (0,0,0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "thick-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_format(predicted_state):\n",
    "    if predicted_state == 0:\n",
    "        state = \"bored\"\n",
    "        color = (0,0,255)\n",
    "    elif predicted_state == 1:\n",
    "        state = \"neutral\"\n",
    "        color = (255,255,255)\n",
    "    else:\n",
    "        state = \"engaged\"\n",
    "        color = (0,255,0)\n",
    "    return state, color\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bronze-object",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_input():\n",
    "    option = -1\n",
    "    while option != 0 and option != 1:\n",
    "        option = int(input(\"Choose input device: \\n0 - Webcam \\n1 - Screen\\n\"))\n",
    "    return option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cross-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def take_frame(option, video):\n",
    "    if option == 0:\n",
    "        \n",
    "        _, frame = video.read()\n",
    "    else:\n",
    "        screenshot = pyautogui.screenshot()\n",
    "        frame = np.array(screenshot)\n",
    "        frame = cv.resize(frame, (1280, 720))\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_RGB2BGR)\n",
    "        \n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "hundred-recruitment",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    nframe = 0\n",
    "    state = \"\"\n",
    "    percentage = 0\n",
    "    color = (0,0,0)\n",
    "    detected_faces = dict()\n",
    "    video = cv.VideoCapture(0)\n",
    "    \n",
    "    option = ask_input()\n",
    "\n",
    "    while True: \n",
    "        frame = take_frame(option, video)\n",
    "        faces_detected = detect_faces(frame)\n",
    "\n",
    "        if type(faces_detected) is not tuple:    \n",
    "            if nframe % 5 == 0:\n",
    "                detected_faces, counter, face_number = init_values(faces_detected, detected_faces)\n",
    "                for face in faces_detected:\n",
    "                    predicted_state, percentage = predict_state(face, frame)\n",
    "\n",
    "                    state, color = assign_format(predicted_state)\n",
    "\n",
    "                    detected_faces[\"msg\"].append(state + \" \" + str(percentage) + \"%\")\n",
    "                    detected_faces[\"color\"].append(color)\n",
    "                    counter[state] += 1\n",
    "                    face_number += 1\n",
    "                    \n",
    "            if \"faces\" in detected_faces:\n",
    "                draw_text(detected_faces, frame, counter)\n",
    "\n",
    "        nframe += 1\n",
    "        cv.imshow(\"VITAL EMO - Q to stop\", frame)\n",
    "\n",
    "\n",
    "        key = cv.waitKey(1)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    video.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compact-liabilities",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Choose input device: \n",
      "0 - Webcam \n",
      "1 - Screen\n",
      " 1\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-primary",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
